{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13c39de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %% [markdown]\n",
    "## Introducción a los datos no estructurados\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bb3525d",
   "metadata": {},
   "source": [
    "### 1. Cargar un archivo de texto y contar la cantidad de palabras.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42b79375",
   "metadata": {},
   "source": [
    "#### a. Importar la librería os y utilizarla para obtener la ruta del archivo:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "808a1285",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "ruta = os.path.join('ruta', 'del', 'archivo', 'texto.txt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1684e01",
   "metadata": {},
   "source": [
    "#### b. Abrir el archivo y leer su contenido:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f80c768",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(ruta, 'r', encoding='utf-8') as f:\n",
    "    contenido = f.read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e86e07c8",
   "metadata": {},
   "source": [
    "#### c. Tokenizar el contenido del archivo en palabras:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c9dc161",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "palabras = nltk.word_tokenize(contenido)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371b0cbe",
   "metadata": {},
   "source": [
    "#### d. Contar la cantidad de palabras:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8766f756",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(palabras)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b76e02b",
   "metadata": {},
   "source": [
    "### 2. Cargar una imagen y mostrar su contenido.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c0301d9",
   "metadata": {},
   "source": [
    "#### a. Importar la librería Pillow y utilizarla para cargar la imagen:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aee1b63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "ruta = os.path.join('ruta', 'del', 'archivo', 'imagen.jpg')\n",
    "\n",
    "imagen = Image.open(ruta)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2ef281a",
   "metadata": {},
   "source": [
    "#### b. Mostrar la imagen en una ventana emergente:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51dd3c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "imagen.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9c16c04",
   "metadata": {},
   "source": [
    "### 1. Leer y visualizar una imagen utilizando Python.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5d3c732",
   "metadata": {},
   "source": [
    "#### a. Importar las bibliotecas necesarias:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "308644c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23663ae2",
   "metadata": {},
   "source": [
    "#### b. Leer la imagen utilizando la función imread de OpenCV:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec303f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "img = cv2.imread('ruta_de_la_imagen.jpg')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c8f4076",
   "metadata": {},
   "source": [
    "#### c. Visualizar la imagen utilizando la función imshow de Matplotlib:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4eb1c3a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(img)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d5d7050",
   "metadata": {},
   "source": [
    "### 2. Leer y procesar un archivo de texto utilizando Python.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd2a065e",
   "metadata": {},
   "source": [
    "#### a. Leer el archivo de texto utilizando la función open de Python:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee3401d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('ruta_del_archivo_de_texto.txt', 'r') as f:\n",
    "    data = f.read()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "720c04c0",
   "metadata": {},
   "source": [
    "#### b. Tokenizar el texto utilizando la función split de Python:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67b1a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = data.split()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bddd8e",
   "metadata": {},
   "source": [
    "#### c. Calcular la frecuencia de cada token utilizando un diccionario de Python:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b461114",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq = {}\n",
    "for token in tokens:\n",
    "    if token in freq:\n",
    "        freq[token] += 1\n",
    "    else:\n",
    "        freq[token] = 1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c811bad2",
   "metadata": {},
   "source": [
    "#### d. Ordenar los tokens según su frecuencia en orden descendente:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2ce9aa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_freq = {k: v for k, v in sorted(freq.items(), key=lambda item: item[1], reverse=True)}\n",
    "print(sorted_freq)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9181d2",
   "metadata": {},
   "source": [
    "### 2. Utilizar la librería spaCy para procesar un texto y obtener información relevante.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0379fca1",
   "metadata": {},
   "source": [
    "#### a. Importar spaCy y cargar el modelo de lenguaje en español:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af720680",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "\n",
    "nlp = spacy.load('es_core_news_sm')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e1cbcd4",
   "metadata": {},
   "source": [
    "#### b. Procesar un texto y obtener información relevante, como entidades nombradas y sus tipos:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78a71835",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"El presidente Alberto Fernández anunció un paquete de medidas económicas para impulsar el crecimiento del país.\"\n",
    "\n",
    "doc = nlp(text)\n",
    "\n",
    "# Print named entities and their labels\n",
    "for ent in doc.ents:\n",
    "    print(ent.text, ent.label_)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1edaa4aa",
   "metadata": {},
   "source": [
    "### 3. Tokenizar un texto utilizando la librería NLTK.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a8575d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "\n",
    "# Tokenize text\n",
    "text = \"Este es un ejemplo de texto para tokenizar.\"\n",
    "tokens = nltk.word_tokenize(text)\n",
    "\n",
    "print(tokens)\n",
    "\n",
    "\n",
    "Ejercicios sobre Introducción a los datos no estructurados\n",
    "Ejercicio 1: Descarga de imágenes de la web\n",
    "a. Utilizar la librería requests de Python para descargar una imagen de la web y guardarla en su computadora.\n",
    "\n",
    "python\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://www.example.com/image.jpg'\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('image.jpg', 'wb') as f:\n",
    "    f.write(response.content)\n",
    "\n",
    "b. Utilizar la librería Pillow para abrir la imagen y visualizarla en su computadora.\n",
    "\n",
    "python\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "image = Image.open('image.jpg')\n",
    "image.show()\n",
    "\n",
    "Ejercicio 2: Descarga de datos de texto\n",
    "a. Utilizar la librería requests de Python para descargar un archivo de texto de la web y guardarlo en su computadora.\n",
    "\n",
    "python\n",
    "\n",
    "import requests\n",
    "\n",
    "url = 'https://www.example.com/data.txt'\n",
    "response = requests.get(url)\n",
    "\n",
    "with open('data.txt', 'w') as f:\n",
    "    f.write(response.text)\n",
    "\n",
    "b. Leer el archivo de texto y realizar alguna operación de procesamiento de texto, como contar la frecuencia de las palabras o eliminar las palabras comunes.\n",
    "\n",
    "python\n",
    "\n",
    "with open('data.txt', 'r') as f:\n",
    "    text = f.read()\n",
    "\n",
    "# contar la frecuencia de las palabras\n",
    "word_counts = {}\n",
    "for word in text.split():\n",
    "    if word in word_counts:\n",
    "        word_counts[word] += 1\n",
    "    else:\n",
    "        word_counts[word] = 1\n",
    "print(word_counts)\n",
    "\n",
    "# eliminar las palabras comunes\n",
    "common_words = ['el', 'la', 'los', 'las', 'de', 'en', 'a', 'y', 'o']\n",
    "words = [word for word in text.split() if word not in common_words]\n",
    "print(' '.join(words))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd4099c",
   "metadata": {},
   "source": [
    "## Procesamiento de datos de texto\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d9fc80c",
   "metadata": {},
   "source": [
    "### 1. Tokenización de texto con NLTK\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fb6fa9",
   "metadata": {},
   "source": [
    "#### a. Instalar la librería NLTK (Natural Language Toolkit)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82aff77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28234996",
   "metadata": {},
   "source": [
    "#### b. Importar NLTK y descargar los recursos necesarios\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03382b61",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d356e0",
   "metadata": {},
   "source": [
    "#### c. Tokenizar una oración utilizando la función word_tokenize de NLTK\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c319905",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = \"El gato está en la alfombra.\"\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adf81408",
   "metadata": {},
   "source": [
    "### 2. Análisis de sentimientos con TextBlob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "436d53e0",
   "metadata": {},
   "source": [
    "#### a. Instalar la librería TextBlob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b51d8667",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install textblob\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5098b48e",
   "metadata": {},
   "source": [
    "#### b. Importar TextBlob y analizar el sentimiento de una oración\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81183d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "text = \"Este libro es excelente.\"\n",
    "blob = TextBlob(text)\n",
    "sentiment = blob.sentiment.polarity\n",
    "print(sentiment)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66d875ff",
   "metadata": {},
   "source": [
    "## Procesamiento de datos de imágenes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaa07327",
   "metadata": {},
   "source": [
    "### 1. Extracción de características con OpenCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d76f9b9",
   "metadata": {},
   "source": [
    "#### a. Instalar la librería OpenCV\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a001568",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install opencv-python\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b5dd22",
   "metadata": {},
   "source": [
    "#### b. Importar OpenCV y cargar una imagen\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a456351e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "img = cv2.imread('ruta_de_la_imagen.jpg')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9946634f",
   "metadata": {},
   "source": [
    "#### c. Convertir la imagen a escala de grises y mostrarla\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bcebdcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "plt.imshow(gray_img, cmap='gray')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "314ac69d",
   "metadata": {},
   "source": [
    "### 2. Redes neuronales convolucionales con TensorFlow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aa6e602",
   "metadata": {},
   "source": [
    "#### a. Instalar TensorFlow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f68dbc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install tensorflow\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0eef00fa",
   "metadata": {},
   "source": [
    "#### b. Importar TensorFlow y cargar un modelo pre-entrenado\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca430007",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "model = tf.keras.applications.MobileNetV2()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b250e6cf",
   "metadata": {},
   "source": [
    "#### c. Cargar una imagen y pasarla por el modelo\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c1a666a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "img_path = 'ruta_de_la_imagen.jpg'\n",
    "img = image.load_img(img_path, target_size=(224, 224))\n",
    "img_array = image.img_to_array(img)\n",
    "img_array = np.expand_dims(img_array, axis=0)\n",
    "img_array = tf.keras.applications.mobilenet_v2.preprocess_input(img_array)\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be0bd0b5",
   "metadata": {},
   "source": [
    "#### d. Obtener las clases y las probabilidades de las predicciones\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5b50e96",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import imagenet_utils\n",
    "\n",
    "results = imagenet_utils.decode_predictions(predictions)\n",
    "for result in results[0]:\n",
    "    print(result)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38229c5",
   "metadata": {},
   "source": [
    "## Introducción a los datos no estructurados\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e31cf470",
   "metadata": {},
   "source": [
    "### 1. Tokenización de texto\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f068c705",
   "metadata": {},
   "source": [
    "#### a. Importar NLTK y descargar los datos necesarios:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2eb9b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3755ac96",
   "metadata": {},
   "source": [
    "#### b. Tokenizar una oración en palabras individuales:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7a54a55",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "sentence = \"Hola a todos, ¿cómo están?\"\n",
    "tokens = word_tokenize(sentence)\n",
    "print(tokens)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5ee2f91",
   "metadata": {},
   "source": [
    "### 2. Análisis de sentimientos\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a953e743",
   "metadata": {},
   "source": [
    "#### a. Importar TextBlob y analizar el sentimiento de una oración:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c0ff12c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "\n",
    "sentence = \"Amo este hermoso día\"\n",
    "blob = TextBlob(sentence)\n",
    "sentiment = blob.sentiment.polarity\n",
    "print(sentiment)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9317732c",
   "metadata": {},
   "source": [
    "#### b. Analizar el sentimiento de un conjunto de comentarios en una lista:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b02dc56",
   "metadata": {},
   "outputs": [],
   "source": [
    "comments = ['Estoy muy feliz hoy', 'Odio estar enfermo', 'Este restaurante es increíble']\n",
    "sentiment_scores = []\n",
    "for comment in comments:\n",
    "    blob = TextBlob(comment)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    sentiment_scores.append(sentiment)\n",
    "print(sentiment_scores)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "219b8c39",
   "metadata": {},
   "source": [
    "### 3. Extracción de características de imágenes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ae3373",
   "metadata": {},
   "source": [
    "#### a. Importar OpenCV y cargar una imagen:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e3e6a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread('ruta_de_la_imagen.jpg')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bf9b3b3",
   "metadata": {},
   "source": [
    "#### b. Convertir la imagen a escala de grises y mostrarla:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e25c1166",
   "metadata": {},
   "outputs": [],
   "source": [
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "cv2.imshow('Imagen en escala de grises', gray_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e42cbb67",
   "metadata": {},
   "source": [
    "### 4. Redes neuronales convolucionales para clasificación de imágenes\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c4fce51",
   "metadata": {},
   "source": [
    "#### a. Importar TensorFlow y Keras y cargar el conjunto de datos MNIST:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be8465",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "mnist = keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cbd4f02",
   "metadata": {},
   "source": [
    "#### b. Preprocesar los datos y construir el modelo de red neuronal convolucional:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9411817e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\n",
    "x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "model = keras.Sequential([\n",
    "    keras.layers.Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(28, 28, 1)),\n",
    "    keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0733ea5c",
   "metadata": {},
   "source": [
    "#### c. Entrenar y evaluar el modelo:\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d29d615d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit(x_train, y_train, epochs=5)\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Accuracy:', test_acc)\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
